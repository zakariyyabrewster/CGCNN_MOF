batch_size: 32
epochs: 60
eval_every_n_epochs: 1
# fine_tune_from: ./training_results/pretraining
fine_tune_from: scratch
log_every_n_steps: 10
gpu: cuda:0
random_seed: 1
task: regression

optim:
  optimizer: Adam
  lr: 0.01
  momentum: 0.9
  weight_decay: 1e-6

model: 
  atom_fea_len: 64
  h_fea_len: 128
  n_conv: 3
  n_h: 1
  drop_ratio: 0.2

data_name: 'CoRE2019'

target_property: Di

dataset:
  root_dir: ./test_datasets/CoRE2019
  label_dir_template: ./test_datasets/id_{target_property}.csv
  fold_dir: ./test_datasets/folds

  max_num_nbr: 12
  radius: 8
  dmin: 0
  step: 0.2


dataloader:
  num_folds: 5
  num_workers: 0


